# -*- coding: utf-8 -*-
"""project_nvidia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CoCfIBo7LkiyLKLQ_QeqbSWpi7xQS9us
"""

!git clone https://github.com/rslim087a/track

!ls track

"""IMPORTING all libraries"""

import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import  MaxPooling2D, Dropout, Flatten, Dense, Conv2D, Input
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from imgaug import augmenters as iaa
from keras.callbacks import EarlyStopping
import seaborn as sns
import cv2
import pandas as pd
import ntpath
import random
import tensorflow as tf
import warnings
warnings.filterwarnings("ignore")

"""making a dataframe for the driving_log.csv

"""

datadir='track'
columns=['center','left','right','steering','throttle','reverse','speed']
data=pd.read_csv(os.path.join(datadir,'driving_log.csv'),names=columns)
pd.set_option('display.max_colwidth',None)
data.head()

"""get the filename from the path
and see the updated data

"""

def pathleaf(path):
    head, tail=ntpath.split(path)
    return tail
data["center"]=data["center"].apply(pathleaf)
data["left"]=data["left"].apply(pathleaf)
data["right"]=data["right"].apply(pathleaf)
data.head()

"""# Visualize the distribution of steering angles

Provide basic statistics for the numerical columns in your dataset.
"""

print(data[['steering','throttle','reverse','speed']].describe())

"""Heatmaps: Display correlations between features (e.g., steering might have low correlation with throttle)."""

plt.figure(figsize=(12,6))
plt.subplot(1,3,1)
plt.hist(data['throttle'],bins=25,edgecolor='black')
plt.title('Throttle Distribution')
plt.xlabel('Throttle')
plt.ylabel('Frequency')

plt.figure(figsize=(12,6))
plt.subplot(1,3,3)
plt.hist(data['speed'],bins=25,edgecolor='black')
plt.title('Speed Distribution')
plt.xlabel('Speed')
plt.ylabel('Frequency')
plt.tight_layout()
plt.show()

plt.figure(figsize=(12,6))
plt.subplot(1,3,2)
plt.hist(data['reverse'],bins=2,edgecolor='black')
plt.title('Reverse Distribution')
plt.xlabel('Reverse')
plt.ylabel('Frequency')

corr=data[['steering','throttle','reverse','speed']].corr()
print(corr)
plt.figure(figsize=(8,6))
sns.heatmap(corr,annot=True,cmap='coolwarm',vmin=-1,vmax=1)
plt.title('Correlation Heatmap of Numerical Features')
plt.show()

"""Understand the relationship between throttle and speed"""

plt.figure(figsize=(10,6))
plt.scatter(data['throttle'],data['speed'],alpha=0.5,color='red')
plt.title('Throttle vs Speed')
plt.xlabel('Throttle')
plt.ylabel('Speed')
plt.show()

"""Histograms: Show the distribution of each feature (e.g., speed might be normally distributed with most values around a central point)."""

num_bins=25
samples_per_bin=400
hist,bins=np.histogram(data['steering'],num_bins)
center=(bins[:-1]+bins[1:])*0.5
plt.bar(center,hist,width=0.05)
plt.plot((np.min(data['steering']),np.max(data['steering'])),(samples_per_bin,samples_per_bin))
plt.xlabel('Steering Angle')
plt.ylabel('Number of Samples')
plt.title('Steering Angle Distribution')

print('total data:',len(data))
print(data.shape)

"""#Removing the biasing of the certain angle in the data

"""

remove_list = []
for j in range(num_bins):
  list_ = []
  for i in range(len(data['steering'])):
    if data['steering'][i] >= bins[j] and data['steering'][i] <= bins[j+1]:
      list_.append(i)
  list_ = shuffle(list_)
  list_ = list_[samples_per_bin:]
  remove_list.extend(list_)
print('removed:', len(remove_list))
data.drop(data.index[remove_list], inplace=True)
print('remaining:', len(data))

"""visulaize the remaning data"""

hist, _=np.histogram(data['steering'],(num_bins))
plt.bar(center,hist,width=0.05)
plt.plot((np.min(data['steering']), np.max(data['steering'])), (samples_per_bin, samples_per_bin))

print(data[['steering','throttle','reverse','speed']].describe())

corr = data[['steering','throttle','reverse','speed']].corr()
print(corr)
plt.figure(figsize=(8,6))
sns.heatmap(corr, annot=True,cmap='coolwarm',vmin=-1,vmax=1)
plt.title('Correlation Heatmap of Numerical Features')
plt.show()

"""# Function to load images and their steering angles"""

def load_img_steering(datadir,df):
  image_path =[]
  steering = []
  for i in range(len(data)):
    indexed_data = data.iloc[i]
    center, left, right = indexed_data[0], indexed_data[1], indexed_data[2]
    image_path.append(os.path.join(datadir, center.strip()))
    steering.append(float(indexed_data[3]))
    # left image append
    image_path.append(os.path.join(datadir,left.strip()))
    steering.append(float(indexed_data[3])+0.15)
    # right image append
    image_path.append(os.path.join(datadir,right.strip()))
    steering.append(float(indexed_data[3])-0.15)
  image_paths = np.asarray(image_path)
  steerings = np.asarray(steering)
  return image_paths, steerings
image_paths, steerings = load_img_steering(datadir + '/IMG', data)

len(image_paths)

len(steerings)

"""# Split the data into training and validation sets"""

X_train,X_valid,y_train,y_valid=train_test_split(image_paths,steerings,test_size=0.2,random_state=6)
print('Training Samples: {}\nValid Samples: {}'.format(len(X_train), len(X_valid)))

"""#Visualize the training set and validation set

"""

fig, axes = plt.subplots(1,2,figsize=(12,4))
axes[0].hist(y_train,bins=num_bins,width=0.05,color='blue')
axes[0].set_title('Training set')
axes[0].set_xlabel('Steering Angle')
axes[0].set_ylabel('Number of Samples')
axes[1].hist(y_valid,bins=num_bins,width=0.05,color='red')
axes[1].set_title('Validation set')
axes[1].set_xlabel('Steering Angle')
axes[1].set_ylabel('Number of Samples')

bins=np.linspace(-1,1,10)
train_counts, _=np.histogram(y_train,bins=bins)
valid_counts, _=np.histogram(y_valid,bins=bins)
train_percentages=100*train_counts/len(y_train)
valid_percentages=100*valid_counts/len(y_valid)
bin_labels=[f'{bins[i]:.2f} to {bins[i+1]:.2f}' for i in range(len(bins) - 1)]
fig,axes=plt.subplots(1,2,figsize=(12,6))
axes[0].pie(train_percentages,labels=bin_labels,autopct='%1.1f%%',colors=plt.cm.Blues(np.linspace(0.3,0.7,len(bins)-1)))
axes[0].set_title('Training Set Distribution')

axes[0].set_xlabel('Steering Angle Range')
axes[1].pie(valid_percentages, labels=bin_labels, autopct='%1.1f%%', colors=plt.cm.Reds(np.linspace(0.3, 0.7, len(bins)-1)))
axes[1].set_title('Validation Set Distribution')
axes[1].set_xlabel('Steering Angle Range')
plt.tight_layout()
plt.show()

"""#Apply zoom augmentation"""

def zoom(image):
  zoom=iaa.Affine(scale=(1,1.3))
  image=zoom.augment_image(image)
  return image

image = image_paths[random.randint(0, 1000)]
original_image = mpimg.imread(image)
zoomed_image = zoom(original_image)

fig, axs = plt.subplots(1, 2, figsize=(15, 10))
fig.tight_layout()

axs[0].imshow(original_image)
axs[0].set_title('Original Image')

axs[1].imshow(zoomed_image)
axs[1].set_title('Zoomed Image')

"""#Apply pan augmentation"""

def pan(image):
  pan=iaa.Affine(translate_percent= {"x" : (-0.1,0.1), "y": (-0.1,0.1)})
  image=pan.augment_image(image)
  return image

image=image_paths[random.randint(0,1000)]
original_image=mpimg.imread(image)
panned_image=pan(original_image)
fig,axs=plt.subplots(1,2,figsize=(15,10))
fig.tight_layout()
axs[0].imshow(original_image)
axs[0].set_title('Original Image')
axs[1].imshow(panned_image)
axs[1].set_title('Panned Image')

"""# Function to randomly adjust image brightness"""

def img_random_brightness(image):
    brightness = iaa.Multiply((0.1, 1.2))
    image = brightness.augment_image(image)
    return image

image = image_paths[random.randint(0, 1000)]
original_image = mpimg.imread(image)
brightness_altered_image = img_random_brightness(original_image)


fig, axs = plt.subplots(1, 2, figsize=(15, 10))
fig.tight_layout()

axs[0].imshow(original_image)
axs[0].set_title('Original Image')

axs[1].imshow(brightness_altered_image)
axs[1].set_title('Brightness altered image ')

"""# Function to randomly flip images"""

def img_random_flip(image, steering_angle):
    image = cv2.flip(image,1)
    steering_angle = -steering_angle
    return image, steering_angle

random_index = random.randint(0, 1000)
image = image_paths[random_index]
steering_angle = steerings[random_index]

original_image = mpimg.imread(image)
flipped_image, flipped_steering_angle = img_random_flip(original_image, steering_angle)

fig, axs = plt.subplots(1, 2, figsize=(15, 10))
fig.tight_layout()

axs[0].imshow(original_image)
axs[0].set_title('Original Image - ' + 'Steering Angle:' + str(steering_angle))

axs[1].imshow(flipped_image)
axs[1].set_title('Flipped Image - ' + 'Steering Angle:' + str(flipped_steering_angle))

"""# Function to apply random augmentations to images"""

def random_augment(image, steering_angle):
    image = mpimg.imread(image)
    if np.random.rand() < 0.5:
      image = pan(image)
    if np.random.rand() < 0.5:
      image = zoom(image)
    if np.random.rand() < 0.5:
      image = img_random_brightness(image)
    if np.random.rand() < 0.5:
      image, steering_angle = img_random_flip(image, steering_angle)

    return image, steering_angle

ncol = 2
nrow = 10

fig, axs = plt.subplots(nrow, ncol, figsize=(15, 50))
fig.tight_layout()

for i in range(10):
  randnum = random.randint(0, len(image_paths) - 1)
  random_image = image_paths[randnum]
  random_steering = steerings[randnum]

  original_image = mpimg.imread(random_image)
  augmented_image, steering = random_augment(random_image, random_steering)

  axs[i][0].imshow(original_image)
  axs[i][0].set_title("Original Image")

  axs[i][1].imshow(augmented_image)
  axs[i][1].set_title("Augmented Image")

"""# Function to preprocess images"""

def img_preprocess(img):
    img = img[60:135,:,:]
    img = cv2.cvtColor(img,cv2.COLOR_RGB2YUV)
    img = cv2.GaussianBlur(img,(3,3),0)
    img = cv2.resize(img,(200,66))
    img = img/255
    return img

image = image_paths[100]
original_image = mpimg.imread(image)
preprocessed_image = img_preprocess(original_image)

fig, axs = plt.subplots(1, 2, figsize=(15, 10))
fig.tight_layout()
axs[0].imshow(original_image)
axs[0].set_title('Original Image')
axs[1].imshow(preprocessed_image)
axs[1].set_title('Preprocessed Image')

"""# Generator function to yield batches of preprocessed images and steering angles"""

def batch_generator(image_paths, steering_ang, batch_size, istraining):
  while True:
    batch_img = []
    batch_steering = []
    for i in range(batch_size):
      random_index = random.randint(0, len(image_paths) - 1)
      if istraining:
        im, steering = random_augment(image_paths[random_index], steering_ang[random_index])
      else:
        im = mpimg.imread(image_paths[random_index])
        steering = steering_ang[random_index]
      im = img_preprocess(im)
      batch_img.append(im)
      batch_steering.append(steering)
    yield (np.asarray(batch_img), np.asarray(batch_steering))

x_train_gen, y_train_gen = next(batch_generator(X_train, y_train, 1, 1))
x_valid_gen, y_valid_gen = next(batch_generator(X_valid, y_valid, 1, 0))

fig, axs = plt.subplots(1, 2, figsize=(15, 10))
fig.tight_layout()

axs[0].imshow(x_train_gen[0])
axs[0].set_title('Training Image')

axs[1].imshow(x_valid_gen[0])
axs[1].set_title('Validation Image')

"""# Define the NVIDIA model architecture"""

def nvidia_model():
    model = Sequential()
    model.add(Input(shape=(66, 200, 3)))
    model.add(Conv2D(24, (5,5), strides=(2, 2), activation='elu'))
    model.add(Conv2D(36, (5,5), strides=(2, 2), activation='elu'))
    model.add(Conv2D(48, (5,5), strides=(2, 2), activation='elu'))
    model.add(Conv2D(64, (3,3), activation='elu'))
    model.add(Conv2D(64, (3,3), activation='elu'))
    model.add(Flatten())
    model.add(Dense(100, activation='elu'))
    model.add(Dense(50, activation='elu'))
    model.add(Dense(10, activation='elu'))
    model.add(Dense(1))
    model.compile(loss='mse', optimizer=Adam(learning_rate=1e-3),metrics=['mse'])
    return model
model = nvidia_model()
print(model.summary())

"""
# Train the model"""

history = model.fit(batch_generator(X_train, y_train, 100, 1),
                                  steps_per_epoch=300,
                                  epochs=10,
                                  validation_data=batch_generator(X_valid, y_valid, 100, 0),
                                  validation_steps=200,
                                  verbose=1,
                                  shuffle = 1)

"""# Preprocess validation images for evaluation
# Evaluate the model on validation data
"""

X_valid_images = []
for img_path in X_valid:
    img = mpimg.imread(img_path)
    img = img_preprocess(img)
    X_valid_images.append(img)
X_valid_images = np.array(X_valid_images)
results = model.evaluate(X_valid_images, y_valid)
print(f"Validation MSE: {results[1]}")

y_pred = model.predict(X_valid_images)
plt.figure(figsize=(10, 6))
plt.scatter(y_valid, y_pred, alpha=0.5)
plt.plot([min(y_valid), max(y_valid)], [min(y_valid), max(y_valid)], 'r')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Predicted vs Actual Values')
plt.show()

plt.figure(figsize=(10,6))
plt.hist(y_train,bins=50,alpha=0.5,label='Actual')
plt.hist(y_valid,bins=50,alpha=0.5,label='Predicted')
plt.legend(loc='upper right')
plt.title('Prediction vs Actual Distribution')
plt.show()

"""# Plot training and validation loss"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['training', 'validation'])
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.show()

"""#saving and downloading the model"""

model.save('model.h5')
from google.colab import files
files.download('model.h5')